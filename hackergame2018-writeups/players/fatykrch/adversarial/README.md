### 对抗深渊

由于之前有看过论文`Towards Evaluating the Robustness of Neural Networks`，以及在tensorflow框架下做过对抗样本生成的实验 [论文作者的代码](https://github.com/carlini/nn_robust_attacks)  
这里尝试在pytorch上重现一下，但是不太懂pytorch的语法，也没有去看它的例子，最终写成了这个鬼样子(见[adversarial.py](adversarial.py))，比出题人的解法写的长了好多2333  

[返回](../)